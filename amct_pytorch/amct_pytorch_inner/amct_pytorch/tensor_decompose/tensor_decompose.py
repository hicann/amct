#!/usr/bin/env python3
# -*- coding: UTF-8 -*-
# ----------------------------------------------------------------------------
# Copyright (c) Huawei Technologies Co., Ltd. 2026. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# 
#     http://www.apache.org/licenses/LICENSE-2.0

# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ----------------------------------------------------------------------------
__all__ = ['auto_decomposition', 'decompose_network']

import os
import stat
import json

import torch
import torch.nn as nn

from ...amct_pytorch.common.decomposition.decomposition import \
    tensor_decomposition
from ...amct_pytorch.common.utils.files import check_files_exist
from ...amct_pytorch.utils.log import LOGGER


def auto_decomposition(model, decompose_info_path=None):
    """
    Function:
        Decompose a trained PyTorch model. Model structure and weights will be
        modified. This function should be called before passing the model
        parameters to optimizer. If torch.nn.parallel.DistributedDataParallel
        (DDP) is used, this function should be called before DDP(model, ...).
        For distributed training, since the decomposition takes some time, it
        is more recommended to call this function once first to get the
        decomposition information file, and save the decomposed weights. After
        that, in each training process, use decompose_network() to decompose
        the model using the saved decomposition information file, and then load
        the saved weights.
        Note that this function only supports convolutions defined with
        torch.nn.Conv2d() and can be obtained by model.named_modules().
    Parameter:
        model: Model to be decomposed, which should be a torch.nn.Module
            object. It is recommended to place the model on cpu when calling
            this function.
        decompose_info_path [Optional]: Output decomposition information file
            path. The file can be used by decompose_network(). The file is
            saved in json format, therefore saving it with a .json extension is
            recommended. No file is saved when the parameter is None (default).
    Return:
        model: The decomposed model.
        changes: A dict containing the Conv2d names before and after the model
            is decomposed, e.g., {'conv1': ['conv1.0', 'conv1.1'], 'conv2':
            ['conv2.0', 'conv2.1'], ...}. Only the changed layers are included.
    """
    LOGGER.logi('auto_decomposition start.')
    decompose_info_path = _check_auto_decomp_input(model, decompose_info_path)
    param_dict = {}
    new_layer_groups = []
    decom_info_list = []
    for layer_name, layer in model.named_modules():
        if not _check_type(layer, nn.Conv2d):
            continue
        LOGGER.logi('Processing: \'{}\''.format(layer_name))
        new_layer_packs, decom_info = _decompose_one_layer(
            layer_name, layer, param_dict)
        if len(new_layer_packs) == 0:
            continue
        new_layer_groups.append([layer_name, new_layer_packs])
        decom_info_list.append(decom_info)
    _save_decom_info(decom_info_list, decompose_info_path)
    model, changes = _replace_layers(model, new_layer_groups)
    LOGGER.logi('auto_decomposition complete.')
    return model, changes


def decompose_network(model, decompose_info_path):
    """
    Function:
        Decompose the structure of a PyTorch model according to the existing
        decomposition information file generated by auto_decomposition().
        This function should be called before passing the model parameters to
        optimizer. If torch.nn.parallel.DistributedDataParallel (DDP) is used,
        this function should be called before DDP(model, ...).
        Note that: (1) This function modifies model structure only, while the
        decomposed weights are not loaded. The weights should be saved after
        calling auto_decomposition(), and can be loaded after calling this
        function. (2) This function only supports convolutions defined with
        torch.nn.Conv2d() and can be obtained by model.named_modules().
    Parameter:
        model: Model to be decomposed, which should be a torch.nn.Module
            object, and should have the same definition with the model used by
            auto_decomposition(). It is recommended to place the model on cpu
            when calling this function.
        decompose_info_path: Input decomposition information file path. The
            file is generated by auto_decomposition().
    Return:
        model: The decomposed model.
        changes: A dict containing the Conv2d names before and after the model
            is decomposed, e.g., {'conv1': ['conv1.0', 'conv1.1'], 'conv2':
            ['conv2.0', 'conv2.1'], ...}. Only the changed layers are included.
    """
    LOGGER.logi('decompose_network start.')
    with open(_check_decom_net_input(model, decompose_info_path), 'r',
              encoding='UTF-8', newline='') as json_file:
        decom_info_list = json.load(json_file)
    named_modules = dict(model.named_modules())
    param_dict = {}
    new_layer_groups = []
    for decom_info in decom_info_list:
        layer_name = decom_info['ori_layer_info']['name']
        if layer_name not in named_modules:
            raise ValueError(
                'Cannot find layer \'{}\' in model.'.format(layer_name))
        layer = named_modules[layer_name]
        if not _check_type(layer, nn.Conv2d):
            raise ValueError('Layer \'{}\' should be a torch.nn.Conv2d object.'
                             .format(layer_name))
        _check_layer_info(layer_name, layer, decom_info['ori_layer_info'])
        mode = decom_info['mode']
        new_layer_packs = []
        for pos in ['first', 'last']:
            new_layer_packs.append(_create_new_layer(
                layer, pos, mode,
                decom_info['decom_nodes'][pos]['weight_shape'], param_dict))
        new_layer_groups.append([layer_name, new_layer_packs])
    model, changes = _replace_layers(model, new_layer_groups)
    LOGGER.logi('decompose_network complete.')
    return model, changes


def _replace_layers(model, new_layer_groups):
    """
    Function:
        Replace original layers in the input model with decomposed layers, and
        save the decomposition information file when needed.
    Parameter:
        model: Input model.
        new_layer_groups: List of original layer names and their corresponding
            new_layer_packs (new layers and the devices of their data to be
            placed).
    Return:
        model: The decomposed model.
        changes: A dict containing the Conv2d names before and after the model
            is decomposed. Only the changed layers are included.
    """
    is_conv2d = _check_type(model, nn.Conv2d)
    changes = {}
    for layer_name, new_layer_packs in new_layer_groups:
        new_layer_list = []
        for new_layer, weight_device, bias_device in new_layer_packs:
            new_layer.weight.data = new_layer.weight.data.to(weight_device)
            if new_layer.bias is not None:
                new_layer.bias.data = new_layer.bias.data.to(bias_device)
            new_layer_list.append(new_layer)
        new_layers = nn.Sequential(*new_layer_list)
        if is_conv2d:
            model = new_layers  # one layer only if is_conv2d
        else:
            _relink_layers(model, layer_name.split('.'), new_layers)
        changes.update(_log_decomposed_layers(model, layer_name, new_layers))
    return model, changes


def _check_auto_decomp_input(model, decompose_info_path):
    """
    Function: Check input parameters for auto_decomposition.
    Parameter:
        model: Input model.
        decompose_info_path: Output decomposition information file path.
    Return:
        decompose_info_path: Standardized decomposition information file path.
    """
    _check_obj_type(model, 'model', nn.Module, 'torch.nn.Module')
    if decompose_info_path is not None:
        _check_obj_type(decompose_info_path, 'decompose_info_path', str)
        decompose_info_path = os.path.realpath(decompose_info_path)
    return decompose_info_path


def _check_decom_net_input(model, decompose_info_path):
    """
    Function: Check input parameters for decompose_network.
    Parameter:
        model: Input model.
        decompose_info_path: Input decomposition information file path.
    Return:
        decompose_info_path: Standardized decomposition information file path.
    """
    _check_obj_type(model, 'model', nn.Module, 'torch.nn.Module')
    _check_obj_type(decompose_info_path, 'decompose_info_path', str)
    decompose_info_path = os.path.realpath(decompose_info_path)
    _check_file_existence(decompose_info_path)
    return decompose_info_path


def _save_decom_info(decom_info_list, decompose_info_path):
    """
    Function: Save decomposition information file.
    Parameter:
        decom_info_list: Decomposition information list.
        decompose_info_path: Output decomposition information file path.
    """
    if len(decom_info_list) == 0:
        msg = 'No tensor meets decomposition conditions.'
        if decompose_info_path is not None:
            msg = '{} Decomposition information file is not saved.'.format(msg)
        LOGGER.logi(msg)
        return
    if decompose_info_path is None:
        return
    save_root = os.path.dirname(decompose_info_path)
    if os.path.isfile(save_root):
        raise IOError('Failed to create path, {} is a file.'.format(
            save_root))
    dir_mode = stat.S_IRWXU + stat.S_IRGRP + stat.S_IXGRP
    file_flags = os.O_WRONLY + os.O_CREAT + os.O_TRUNC
    file_mode = stat.S_IRUSR + stat.S_IWUSR + stat.S_IRGRP
    os.makedirs(save_root, dir_mode, exist_ok=True)
    check_files_exist([decompose_info_path])
    with os.fdopen(os.open(decompose_info_path, file_flags, file_mode), 'w',
                   encoding='UTF-8', newline='') as json_file:
        json.dump(decom_info_list, json_file, indent='\t')
    LOGGER.logi('Decomposition information file is saved to: {}'.format(
        decompose_info_path))


def _log_decomposed_layers(model, ori_layer_name, new_layers):
    """
    Function: Write log for the layers before and after decomposition.
    Parameter:
        model: Input model.
        ori_layer_name: Original layer name.
        new_layers: Newly created layers.
    Return:
        change: A dict containing the Conv2d names before and after the current
            layer is decomposed, e.g., {'conv1': ['conv1.0', 'conv1.1']}.
    """
    new_layer_names = []
    module_names = {v: k for k, v in model.named_modules()}
    for new_layer in new_layers:
        new_layer_names.append(module_names[new_layer])
    LOGGER.logi('Decompose: \'{}\' -> {}'.format(
        ori_layer_name, new_layer_names))
    change = {ori_layer_name: new_layer_names}
    return change


def _check_type(obj, target_type):
    """
    Function: Check the type of an object. Inheritance is not included.
    Parameter:
        obj: Object to check.
        target_type: Target type.
    Return:
        Whether the object matches the type.
    """
    return isinstance(obj, target_type) 


def _fmt_param(param, using_list=False):
    """
    Function: Change a layer parameter to standard format.
    Parameter:
        param: Parameter of a layer.
        using_list: Use list instead of tuple.
    Return:
        param: The changed parameter.
    """
    if _check_type(param, int):
        return [param, param] if using_list else (param, param)
    if using_list:
        if _check_type(param, tuple):
            return list(param)
    else:
        if _check_type(param, list):
            return tuple(param)
    return param


def _get_layer_info(layer_name, layer):
    """
    Function: Get the information of a layer.
    Parameter:
        layer_name: Layer name.
        layer: The layer to process.
    Return:
        Information of the layer.
    """
    return {
        'name': layer_name,
        'in_channels': layer.in_channels,
        'out_channels': layer.out_channels,
        'kernel_size': _fmt_param(layer.kernel_size, True),
        'stride': _fmt_param(layer.stride, True),
        'dilation': _fmt_param(layer.dilation, True),
        'groups': layer.groups,
    }


def _check_param(layer_name, layer_info, param_name, param):
    """
    Function: Check whether a layer parameter matches the one in layer
        information.
    Parameter:
        layer_name: Layer name.
        layer_info: Layer information.
        param_name: Parameter name.
        param: Value of the parameter.
    """
    if layer_info[param_name] != param:
        raise ValueError(
            '{} of layer \'{}\' does not match the original model, please '
            'check the model definition and the decomposition information '
            'file.'.format(param_name, layer_name))


def _check_layer_info(layer_name, layer, layer_info):
    """
    Function: Check whether all the parameters of a layer match the layer
        information.
    Parameter:
        layer_name: Layer name.
        layer: Layer to be checked.
        layer_info: Layer information.
    """
    kernel_size = _fmt_param(layer.kernel_size, True)
    stride = _fmt_param(layer.stride, True)
    dilation = _fmt_param(layer.dilation, True)
    _check_param(layer_name, layer_info, 'in_channels', layer.in_channels)
    _check_param(layer_name, layer_info, 'out_channels', layer.out_channels)
    _check_param(layer_name, layer_info, 'kernel_size', kernel_size)
    _check_param(layer_name, layer_info, 'stride', stride)
    _check_param(layer_name, layer_info, 'dilation', dilation)
    _check_param(layer_name, layer_info, 'groups', layer.groups)


def _decompose_one_layer(layer_name, layer, param_dict):
    """
    Function: Decompose a single convolution layer, and apply decomposed
        weights on the decomposed layers.
    Parameter:
        layer_name: Original convolution layer name.
        layer: Original convolution layer.
        param_dict: Dict to save information of the processed parameters (in
            order to handle shared parameters).
    Return:
        new_layer_packs: A list of new layers and the devices of their data to
            be placed.
        decom_info: Decomposing information of the decomposed layer.
    """
    if layer.weight in param_dict:
        decom_res = param_dict[layer.weight]['decom_res']
    else:
        if layer.weight.data.dtype not in [
                torch.float16, torch.float32, torch.float64]:
            LOGGER.logw('Unsupported data type {} of layer \'{}\', ignored.'
                        .format(layer.weight.data.dtype, layer_name))
            return [], {}
        # C_out, C_in, K_h, K_w
        tensor = layer.weight.data.cpu().to(torch.float64).numpy()
        decom_res = tensor_decomposition(
            tensor, _fmt_param(layer.stride),
            layer.groups, _fmt_param(layer.dilation))
        param_dict[layer.weight] = {'decom_res': decom_res}
    mode = decom_res.get('mode').name
    if mode == 'UNCHANGE':
        return [], {}
    new_layer_packs = []
    decom_info = {
        'ori_layer_info': _get_layer_info(layer_name, layer), 'mode': mode}
    decom_nodes = {}
    for pos in ['first', 'last']:
        weight = decom_res.get(pos)
        new_layer_pack = _create_new_layer(
            layer, pos, mode, weight.shape, param_dict)
        new_layer = new_layer_pack[0]
        new_layer.weight.data = _modify_memory_format(_modify_data_type(
            torch.from_numpy(weight).contiguous(), layer.weight.data),
            layer.weight.data)
        if new_layer.bias is not None:
            new_bias = layer.bias.data.detach().clone()
            new_layer.bias.data = new_bias.cpu()
        new_layer_packs.append(new_layer_pack)
        decom_nodes[pos] = {'weight_shape': weight.shape}
    decom_info['decom_nodes'] = decom_nodes
    return new_layer_packs, decom_info


def _create_new_layer(ori_layer, pos, mode, weight_shape, param_dict):
    """
    Function: Create a new convolution layer based on decomposition
        information. Weights of the created layer is not updated.
    Parameter:
        ori_layer: Original convolution layer.
        pos: Order flag of the decomposed weights.
        mode: Mode of the decomposition result.
        weight_shape: Shape of the decomposed weights.
        param_dict: Dict to save information of the processed parameters (in
            order to handle shared parameters).
    Return:
        new_layer_pack: A list containing the created new layer and the devices
            of its data to be placed.
    """
    if (pos == 'first' and mode in ['FCSK', 'SCFK']) or \
            (pos == 'last' and mode in ['FCFK', 'SCSK']):
        modify_idx = 1  # width index
    else:
        modify_idx = 0  # height index
    stride = _modify_attr(ori_layer.stride, modify_idx, 1)
    padding = _modify_attr(ori_layer.padding, modify_idx, 0)
    dilation = _modify_attr(ori_layer.dilation, modify_idx, 1)
    bias = (ori_layer.bias is not None) if pos == 'last' else False
    new_layer = torch.nn.Conv2d(
        in_channels=weight_shape[1],
        out_channels=weight_shape[0],
        kernel_size=(weight_shape[2], weight_shape[3]),
        stride=stride,
        padding=padding,
        dilation=dilation,
        groups=ori_layer.groups,
        bias=bias,
        padding_mode=ori_layer.padding_mode)
    bias_device = None
    if ori_layer.weight in param_dict and pos in param_dict[ori_layer.weight]:
        new_layer.weight = param_dict[ori_layer.weight][pos]
    else:
        new_layer.weight.data = _modify_memory_format(_modify_data_type(
            new_layer.weight.data, ori_layer.weight.data),
            ori_layer.weight.data)
        if ori_layer.weight not in param_dict:
            param_dict[ori_layer.weight] = {}
        param_dict[ori_layer.weight][pos] = new_layer.weight
    if bias:
        if ori_layer.bias in param_dict:
            new_layer.bias = param_dict[ori_layer.bias]
        else:
            new_layer.bias.data = _modify_data_type(
                new_layer.bias.data, ori_layer.bias.data)
            param_dict[ori_layer.bias] = new_layer.bias
        bias_device = ori_layer.bias.data.device
    new_layer_pack = [new_layer, ori_layer.weight.data.device, bias_device]
    return new_layer_pack


def _relink_layers(module, layer_name_split, new_layers):
    """
    Function: Replace a specified layer in a model with new layers.
    Parameter:
        module: The torch.nn.Module object to be modified.
        layer_name_split: Split of the name of the layer to be replaced.
        new_layers: The new layers to be replaced with.
    """
    if len(layer_name_split) == 1:
        if layer_name_split[-1].isnumeric():
            module[int(layer_name_split[-1])] = new_layers
        else:
            setattr(module, layer_name_split[-1], new_layers)
    else:
        for child_name, child_module in module.named_children():
            if child_name == layer_name_split[0]:
                _relink_layers(child_module, layer_name_split[1:], new_layers)


def _modify_attr(attr, modify_idx, def_val):
    """
    Function: Modify a specified index of a convolution attribute to its
        default value.
    Parameter:
        attr: Attribute to be modified.
        modify_idx: Index of the attribute to be modified to default value.
        def_val: Default value of the attribute.
    Return:
        new_attr: The modified attribute.
    """
    if _check_type(attr, int):
        new_attr = [attr, attr]
    else:
        if not (_check_type(attr, list) or _check_type(attr, tuple)):
            raise ValueError('Unknown attribute format: {}.'.format(attr))
        if len(attr) == 1:
            new_attr = [attr[0], attr[0]]
        elif len(attr) == 2:
            new_attr = [attr[0], attr[1]]
        else:
            raise ValueError('Wrong attribute shape: {}.'.format(attr))
    new_attr[modify_idx] = def_val
    new_attr = tuple(new_attr)
    return new_attr


def _modify_memory_format(src_tensor, tar_tensor):
    """
    Function: Modify the memory format of source tensor according to target
        tensor. Only 4D tensor is supported.
    Parameter:
        src_tensor: Source tensor.
        tar_tensor: Target tensor.
    Return:
        src_tensor: The modified source tensor.
    """
    torch_ver = torch.__version__.split('.')[:2]
    torch_ver = list(map(int, torch_ver))
    # Torch supports memory_format since version 1.5.0
    if torch_ver[0] < 1 or (torch_ver[0] == 1 and torch_ver[1] < 5):
        return src_tensor
    # If both formats are contiguous, use torch.contiguous_format
    for memory_format in [torch.contiguous_format, torch.channels_last]:
        if tar_tensor.is_contiguous(memory_format=memory_format):
            src_tensor = src_tensor.to(memory_format=memory_format)
            break
    return src_tensor


def _modify_data_type(src_tensor, tar_tensor):
    """
    Function: Modify the data type of source tensor according to target tensor.
    Parameter:
        src_tensor: Source tensor.
        tar_tensor: Target tensor.
    Return:
        src_tensor: The modified source tensor.
    """
    src_type = src_tensor.dtype
    tar_type = tar_tensor.dtype
    f16, f32, f64 = torch.float16, torch.float32, torch.float64
    if (src_type == f64 and tar_type in [f16, f32]) or \
            (src_type == f32 and tar_type == f16):
        tar_data_info = torch.finfo(tar_type)
        src_tensor = src_tensor.clamp(tar_data_info.min, tar_data_info.max)
    return src_tensor.to(tar_type)


def _check_obj_type(obj, obj_name, expected_type, expected_type_name=None):
    """
    Function: Check object type.
    Parameter:
        obj: The object to check.
        obj_name: Name of the object.
        expected_type: Expected type of the object.
        expected_type_name: Name of the object's expected type.
    """
    if not isinstance(obj, expected_type):
        if expected_type_name is None:
            expected_type_name = expected_type.__name__
        raise TypeError(
            '\'{}\' type is wrong. Expected type \'{}\', got \'{}\' instead.'
            .format(obj_name, expected_type_name, type(obj).__name__))


def _check_file_existence(file_path):
    """
    Function: Check whether a file exists.
    Parameter:
        file_path: File path to check.
    """
    if not os.access(file_path, os.F_OK):
        raise IOError('{} does not exist!'.format(file_path))
    if not os.path.isfile(file_path):
        raise IOError('{} is not a file!'.format(file_path))
